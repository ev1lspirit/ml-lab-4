## Что внутри репозитория
- `iris_multiclass_analysis.py` — основной скрипт с EDA, подбором моделей и сравнением стратегий.
- `figures/` — сохраняются графики EDA: `pairplot.png`, `boxplots.png`, `correlation.png`, `petal_scatter.png`.
- `model_results.csv` — таблица с итоговыми метриками и лучшими гиперпараметрами по всем запускам.

## Запуск
```bash
python3 iris_multiclass_analysis.py
```
После выполнения скрипта в корне появится `model_results.csv`, а в каталоге `figures/` — визуализации EDA

## EDA
Для проведения ЕДА построил 3 графика: корреляция, скаттерплот длины от ширины внутренней доли околоцветника, а также ящики с усами распределений длины и ширины наружной и внутренней доли околоцветника
По результату анализа выяснил, что пара petal_length и petal_width почти линейно отделяет класс setosa, в то время как классы versicolor и virginica слегка пересекаются по лепесткам.
Чашелистики менее информативны и коррелируют с признаками лепестков
Масштабирование заметно помогает методам, чувствительным к масштабу расстояний и коэффициентов (SVM, KNN, логрегрессия).

## Эксперименты и результаты
Метрика: AUC-ROC по 5-fold Stratified CV; время — полное время подбора/обучения модели.

| База + стратегия      | CV AUC | AUC (CV predict) | Время, с |
|-----------------------|--------|------------------|----------|
| SVM + ECOC            | 0.9950 | **0.9970**       | 0.295    |
| SVM + OvR             | 0.9950 | 0.9969           | 0.283    |
| SVM + OvO             | 0.9947 | 0.9955           | 0.218    |
| KNN + OvR             | 0.9940 | 0.9953           | 0.353    |
| KNN + ECOC            | 0.9940 | 0.9953           | 0.457    |
| Logistic Regression OvO| 0.9947 | 0.9952           | **0.065**|
| Logistic Regression OvR| 0.9913 | 0.9933           | 0.082    |
| Naive Bayes OvR       | 0.9893 | 0.9909           | 0.054    |
| Naive Bayes ECOC      | 0.9883 | 0.9908           | 0.054    |
| Decision Tree OvR     | 0.9820 | 0.9820           | 0.420    |

Замечания:
У OvO и SVM/KNN отсутствует predict_proba, поэтому для AUC использованы decision_function с softmax.
Время включает подбор гиперпараметров по заданной сетке и 5-fold CV.

## Итоговые выводы
- Лучшее качество: SVM + ECOC (AUC 0.9970), близко SVM + OvR/OvO.
- KNN устойчив на уровне 0.995 AUC после масштабирования.
- Naive Bayes и Decision Tree заметно уступают по AUC, но работают без масштабирования и обучаются мгновенно.
- Признаки лепестков критичны; при ограничении числа признаков можно сохранить почти весь сигнал, исключив менее информативные sepal-поля.
